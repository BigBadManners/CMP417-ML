{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04802c3",
   "metadata": {},
   "source": [
    "Import the libraries we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b16ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c6094",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('CMP417_testing dataset.csv')\n",
    "train_data = pd.read_csv('CMP417_training dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "train_data[\"proto\"], train_protocols = pd.factorize(train_data[\"proto\"])\n",
    "train_data[\"service\"], train_services = pd.factorize(train_data[\"service\"])\n",
    "train_data[\"state\"], train_states = pd.factorize(train_data[\"state\"])\n",
    "train_data[\"attack_cat\"], train_attacks = pd.factorize(train_data[\"attack_cat\"])\n",
    "\n",
    "test_data[\"proto\"], test_protocols = pd.factorize(test_data[\"proto\"])\n",
    "test_data[\"service\"], test_services = pd.factorize(test_data[\"service\"])\n",
    "test_data[\"state\"], test_states = pd.factorize(test_data[\"state\"])\n",
    "test_data[\"attack_cat\"], test_attacks = pd.factorize(test_data[\"attack_cat\"])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:, :train_data.shape[1]-1]\n",
    "y_train = train_data.iloc[:, train_data.shape[1]-1:]\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "X_test = test_data.iloc[:, :test_data.shape[1]-1]\n",
    "y_test = test_data.iloc[:, test_data.shape[1]-1:]\n",
    "\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "labels = pd.concat([pd.DataFrame(train_data), pd.DataFrame(test_data)])\n",
    "labels = labels.iloc[:, labels.shape[1]-1:]\n",
    "labels = labels.values.ravel()\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_default = RandomForestClassifier(n_jobs=-1, random_state=3, n_estimators=102) # params provided by Dr. Kang and Dr. Kavianpour\n",
    "trained_model = clf_default.fit(X_train, y_train)\n",
    "y_probabilities = clf_default.predict_proba(X_test)\n",
    "print(f'Score: {trained_model.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_default.predict(X_test)\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "error = zero_one_loss(y_test, y_pred)\n",
    "print(f'Error: {error}')\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a981fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(f'Confusion matrix:\\n {results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c149743",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cd, square=True, annot=True, fmt='d', cbar=True)\n",
    "plt.xlabel('True label Predicted')\n",
    "plt.ylabel('predicted label Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba45a90",
   "metadata": {},
   "source": [
    "The training model seems to be a bit Marmite on the data. It's not a perfect 80:20 split, so let's concatenate the dataframes, and then try to split them using train_test_split instead..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_data, test_data])\n",
    "\n",
    "df[\"proto\"], protocols= pd.factorize(df[\"proto\"])\n",
    "df[\"service\"], services = pd.factorize(df[\"service\"])\n",
    "df[\"state\"], flags    = pd.factorize(df[\"state\"])\n",
    "df[\"attack_cat\"], attacks = pd.factorize(df[\"attack_cat\"])\n",
    "\n",
    "features= df.iloc[:,:df.shape[1]-1]\n",
    "labels= df.iloc[:,df.shape[1]-1:]\n",
    "labels= labels.values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.8, test_size=0.2)\n",
    "print (\"X_train, y_train:\", X_train.shape, y_train.shape)\n",
    "print (\"X_test, y_test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18335aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=3, n_estimators=102) # params provided by Dr. Kang and Dr. Kavianpour\n",
    "trained_model = clf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Score: {trained_model.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "error = zero_one_loss(y_test, y_pred)\n",
    "print(f'Error: {error}')\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb30e0",
   "metadata": {},
   "source": [
    "That error value looks much better! Although, there's still some dependence on what data it gets fed from the split. It could be lower, or it could be a little higher. This is due to the distribution of test/train data being stochastic - distributed at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(f'Confusion matrix:\\n {results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cd, square=True, annot=True, fmt='d', cbar=True)\n",
    "plt.xlabel('True label Predicted')\n",
    "plt.ylabel('predicted label Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1034503",
   "metadata": {},
   "source": [
    "Now, let's optimise this, and see if the optimised parameters can reduce the margin of error further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d369d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    \"n_estimators\": [5,10,50,100,250],\n",
    "    \"max_depth\":[2, 4, 8, 16],\n",
    "    \"warm_start\": [True, False],\n",
    "    \"n_jobs\": [1, None, -1],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\", None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \n",
    "}\n",
    "cv = GridSearchCV(clf,params,cv=5)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(result):\n",
    "    print(f'Best params: {result.best_params_}\\n')\n",
    "    mean_score = result.cv_results_['mean_test_score']\n",
    "    std_score = result.cv_results_['std_test_score']\n",
    "    parameters = result.cv_results_['params']\n",
    "    \n",
    "    for mean, std, params in zip(mean_score,std_score,parameters):\n",
    "        print(f'{round(mean,3)} + or - {round(std,3)} for the {params}')\n",
    "        \n",
    "display(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445de0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tuned = RandomForestClassifier(criterion=\"entropy\", max_depth=8, max_features=None, n_estimators=10, n_jobs=1, warm_start=True) # params provided by Dr. Kang and Dr. Kavianpour\n",
    "trained_model_tuned = clf_tuned.fit(X_train, y_train)\n",
    "print(f'Score: {trained_model_tuned.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2069b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuned = clf_tuned.predict(X_test)\n",
    "y_probabilities = clf_tuned.predict_proba(X_test)\n",
    "results = confusion_matrix(y_test, y_pred_tuned)\n",
    "error = zero_one_loss(y_test, y_pred_tuned)\n",
    "print(f'Error: {error}')\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15768cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = pd.crosstab(y_test, y_pred_tuned, rownames=['Actual'], colnames=['Predicted'])\n",
    "print(f'Confusion matrix:\\n {results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ff4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cd, square=True, annot=True, fmt='d', cbar=True)\n",
    "plt.xlabel('True label Predicted')\n",
    "plt.ylabel('predicted label Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be14b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve\n",
    "acc = accuracy_score(y_test, y_pred_tuned)\n",
    "print(\"Accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f6dac",
   "metadata": {},
   "source": [
    "While the confusion matrix shows the classifier could correctly classify every point in the data set, we can evaluate performance further using ROC curves and the area under that curve (AUC).\n",
    "\n",
    "The Receiver Operating Characteristic curve represents the model's True Positive Rate (TPR) against its False Positive Rate (FPR). For a perfect classifier, there are no false positives, and the ROC curve's AUC will be 1. In other words, the more area under the curve, the better the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4061c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary = []\n",
    "y_score = []\n",
    "for n in range(len(y_test)):\n",
    "    l = y_test[n]\n",
    "    y_score.append(sum(y_probabilities[n,:])-y_probabilities[n,0])\n",
    "    if attacks[l] == 'Normal':\n",
    "        assert(l == 0)\n",
    "        y_test_binary.append(0)\n",
    "    else:\n",
    "        y_test_binary.append(1)\n",
    "y_test_binary = np.array(y_test_binary)\n",
    "y_score = np.array(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b875ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threstholds = roc_curve(y_test_binary, y_score, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "precision, recall, thresholds_precision_recall = precision_recall_curve(y_test_binary, y_score, pos_label=1)\n",
    "auc_pr = auc(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='AUC = %0.6f' % (roc_auc))\n",
    "plt.xlabel('False Positive Rate (1-specificity)')\n",
    "plt.ylabel('True Positive Rate (sensitivity)')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.title('Receiver Operating Characteristic (ROC) curve (for detecting classified disruptive events)')\n",
    "plt.legend(loc=\"lower right\", prop={'size': 'small'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(recall, precision, label=\"AUC = %0.6f\" % (roc_auc))\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.title('Precision Recall Curve (for detecting attacks of any kind)')\n",
    "plt.legend(loc=\"lower right\", prop={'size': 'small'})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
